{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Similaridade por Cosseno\n",
    "\n",
    "Neste documento, vamos explorar o conceito de similaridade de documentos por cosseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import machado\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from nltk.stem.snowball import PortugueseStemmer\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar importando os textos de Machado de Assis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = [machado.raw(id) for id in machado.fileids()]\n",
    "len(textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tok_textos = [WordPunctTokenizer().tokenize(t) for t in textos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de tokenizar, vamos extrair o vocabulário dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'Semeei', u'obrigaria', u'arrulhou']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = []\n",
    "for t in tok_textos:\n",
    "    vocab += list(set(t))\n",
    "\n",
    "vocab = list(set(vocab))\n",
    "print(len(vocab))\n",
    "vocab[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = nltk.TextCollection(tok_textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = \"Lamartine elixir harpa\"\n",
    "qt = WordPunctTokenizer().tokenize(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3b9e58369710>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfidf_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtok_textos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtok_textos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "tfidf_matrix = np.zeros((len(tok_textos),len(qt)))\n",
    "for j,w in enumerate(qt):\n",
    "    for i, d in enumerate(tok_textos):\n",
    "        tfidf_matrix[i,j] = T.tf_idf(w,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 1),\n",
       " (0.0, 2),\n",
       " (0.0, 3),\n",
       " (0.0, 5),\n",
       " (0.0, 6),\n",
       " (0.0, 7),\n",
       " (0.0, 8),\n",
       " (0.0, 9),\n",
       " (0.0, 10),\n",
       " (0.0, 11),\n",
       " (0.0, 12),\n",
       " (0.0, 13),\n",
       " (0.0, 14),\n",
       " (0.0, 15),\n",
       " (0.0, 17),\n",
       " (0.0, 18),\n",
       " (0.0, 19),\n",
       " (0.0, 20),\n",
       " (0.0, 21),\n",
       " (0.0, 22),\n",
       " (0.0, 23),\n",
       " (0.0, 24),\n",
       " (0.0, 25),\n",
       " (0.0, 26),\n",
       " (0.0, 27),\n",
       " (0.0, 28),\n",
       " (0.0, 29),\n",
       " (0.0, 30),\n",
       " (0.0, 31),\n",
       " (0.0, 32),\n",
       " (0.0, 33),\n",
       " (0.0, 34),\n",
       " (0.0, 35),\n",
       " (0.0, 36),\n",
       " (0.0, 37),\n",
       " (0.0, 38),\n",
       " (0.0, 39),\n",
       " (0.0, 40),\n",
       " (0.0, 42),\n",
       " (0.0, 43),\n",
       " (0.0, 44),\n",
       " (0.0, 45),\n",
       " (0.0, 46),\n",
       " (0.0, 47),\n",
       " (0.0, 48),\n",
       " (0.0, 49),\n",
       " (0.0, 50),\n",
       " (0.0, 51),\n",
       " (0.0, 52),\n",
       " (0.0, 53),\n",
       " (0.0, 54),\n",
       " (0.0, 55),\n",
       " (0.0, 56),\n",
       " (0.0, 57),\n",
       " (0.0, 58),\n",
       " (0.0, 59),\n",
       " (0.0, 60),\n",
       " (0.0, 61),\n",
       " (0.0, 62),\n",
       " (0.0, 63),\n",
       " (0.0, 64),\n",
       " (0.0, 65),\n",
       " (0.0, 66),\n",
       " (0.0, 67),\n",
       " (0.0, 68),\n",
       " (0.0, 69),\n",
       " (0.0, 70),\n",
       " (0.0, 71),\n",
       " (0.0, 72),\n",
       " (0.0, 73),\n",
       " (0.0, 74),\n",
       " (0.0, 75),\n",
       " (0.0, 76),\n",
       " (0.0, 77),\n",
       " (0.0, 78),\n",
       " (0.0, 79),\n",
       " (0.0, 81),\n",
       " (0.0, 82),\n",
       " (0.0, 83),\n",
       " (0.0, 84),\n",
       " (0.0, 86),\n",
       " (0.0, 87),\n",
       " (0.0, 88),\n",
       " (0.0, 89),\n",
       " (0.0, 90),\n",
       " (0.0, 91),\n",
       " (0.0, 92),\n",
       " (0.0, 93),\n",
       " (0.0, 94),\n",
       " (0.0, 95),\n",
       " (0.0, 96),\n",
       " (0.0, 97),\n",
       " (0.0, 98),\n",
       " (0.0, 99),\n",
       " (0.0, 100),\n",
       " (0.0, 101),\n",
       " (0.0, 102),\n",
       " (0.0, 103),\n",
       " (0.0, 104),\n",
       " (0.0, 105),\n",
       " (0.0, 106),\n",
       " (0.0, 107),\n",
       " (0.0, 108),\n",
       " (0.0, 109),\n",
       " (0.0, 110),\n",
       " (0.0, 111),\n",
       " (0.0, 112),\n",
       " (0.0, 113),\n",
       " (0.0, 114),\n",
       " (0.0, 115),\n",
       " (0.0, 116),\n",
       " (0.0, 117),\n",
       " (0.0, 118),\n",
       " (0.0, 119),\n",
       " (0.0, 120),\n",
       " (0.0, 121),\n",
       " (0.0, 122),\n",
       " (0.0, 123),\n",
       " (0.0, 124),\n",
       " (0.0, 126),\n",
       " (0.0, 127),\n",
       " (0.0, 128),\n",
       " (0.0, 129),\n",
       " (0.0, 130),\n",
       " (0.0, 131),\n",
       " (0.0, 132),\n",
       " (0.0, 133),\n",
       " (0.0, 134),\n",
       " (0.0, 135),\n",
       " (0.0, 136),\n",
       " (0.0, 137),\n",
       " (0.0, 140),\n",
       " (0.0, 141),\n",
       " (0.0, 142),\n",
       " (0.0, 143),\n",
       " (0.0, 144),\n",
       " (0.0, 145),\n",
       " (0.0, 146),\n",
       " (0.0, 147),\n",
       " (0.0, 148),\n",
       " (0.0, 149),\n",
       " (0.0, 150),\n",
       " (0.0, 151),\n",
       " (0.0, 153),\n",
       " (0.0, 154),\n",
       " (0.0, 155),\n",
       " (0.0, 156),\n",
       " (0.0, 157),\n",
       " (0.0, 158),\n",
       " (0.0, 159),\n",
       " (0.0, 160),\n",
       " (0.0, 161),\n",
       " (0.0, 162),\n",
       " (0.0, 163),\n",
       " (0.0, 164),\n",
       " (0.0, 165),\n",
       " (0.0, 166),\n",
       " (0.0, 167),\n",
       " (0.0, 168),\n",
       " (0.0, 169),\n",
       " (0.0, 170),\n",
       " (0.0, 171),\n",
       " (0.0, 172),\n",
       " (0.0, 173),\n",
       " (0.0, 174),\n",
       " (0.0, 175),\n",
       " (0.0, 177),\n",
       " (0.0, 178),\n",
       " (0.0, 179),\n",
       " (0.0, 180),\n",
       " (0.0, 181),\n",
       " (0.0, 182),\n",
       " (0.0, 183),\n",
       " (0.0, 184),\n",
       " (0.0, 187),\n",
       " (0.0, 188),\n",
       " (0.0, 189),\n",
       " (0.0, 190),\n",
       " (0.0, 191),\n",
       " (0.0, 192),\n",
       " (0.0, 195),\n",
       " (0.0, 196),\n",
       " (0.0, 197),\n",
       " (0.0, 198),\n",
       " (0.0, 199),\n",
       " (0.0, 200),\n",
       " (0.0, 201),\n",
       " (0.0, 202),\n",
       " (0.0, 203),\n",
       " (0.0, 204),\n",
       " (0.0, 205),\n",
       " (0.0, 206),\n",
       " (0.0, 207),\n",
       " (0.0, 208),\n",
       " (0.0, 209),\n",
       " (0.0, 210),\n",
       " (0.0, 211),\n",
       " (0.0, 212),\n",
       " (0.0, 213),\n",
       " (0.0, 214),\n",
       " (0.0, 215),\n",
       " (0.0, 219),\n",
       " (0.0, 220),\n",
       " (0.0, 221),\n",
       " (0.0, 223),\n",
       " (0.0, 224),\n",
       " (0.0, 225),\n",
       " (0.0, 226),\n",
       " (0.0, 227),\n",
       " (0.0, 228),\n",
       " (0.0, 230),\n",
       " (0.0, 231),\n",
       " (0.0, 233),\n",
       " (0.0, 234),\n",
       " (0.0, 235),\n",
       " (0.0, 236),\n",
       " (0.0, 237),\n",
       " (0.0, 239),\n",
       " (0.0, 241),\n",
       " (0.0, 242),\n",
       " (0.0, 243),\n",
       " (0.0, 244),\n",
       " (0.0, 245),\n",
       " (0.54677079862588274, 16),\n",
       " (0.54677079862588274, 125),\n",
       " (0.54677079862588274, 152),\n",
       " (0.54677079862588274, 176),\n",
       " (0.54677079862588274, 194),\n",
       " (0.54677079862588274, 232),\n",
       " (0.5625219865810609, 80),\n",
       " (0.5625219865810609, 139),\n",
       " (0.5625219865810609, 186),\n",
       " (0.5625219865810609, 216),\n",
       " (0.5625219865810609, 218),\n",
       " (0.5625219865810609, 240),\n",
       " (0.62016990283543361, 41),\n",
       " (0.62016990283543361, 85),\n",
       " (0.62016990283543361, 138),\n",
       " (0.62016990283543361, 229),\n",
       " (0.62016990283543361, 238),\n",
       " (0.63237752564977234, 222),\n",
       " (0.66076127296622689, 193),\n",
       " (0.78446752107215301, 4),\n",
       " (0.78446752107215301, 217),\n",
       " (0.94313934844743286, 185),\n",
       " (0.94345623925738287, 0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "MN = array([r/norm(r) if norm(r) !=0 else np.zeros(len(r)) for r in tfidf_matrix])\n",
    "def rank(q):\n",
    "    return [np.dot(q,r) for r in MN]\n",
    "qv = np.array([T.tf_idf(w,qt) for w in qt])\n",
    "qv /= norm(qv)\n",
    "r = rank(qv)\n",
    "v=zip(r,range(len(tok_textos)))\n",
    "sorted(v) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'toca' in tok_textos[184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd=nltk.FreqDist(WordPunctTokenizer().tokenize(textos[0]))\n",
    "fd['Lamartine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4383729125613106e-05"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.tf(\"Lamartine\",WordPunctTokenizer().tokenize(textos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4383729125613106e-05"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./len(WordPunctTokenizer().tokenize(textos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.TextCollection??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.LazyConcatenation??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index...\n",
      "Displaying 22 of 22 matches:\n",
      ". A sua fala deve ser um murmúrio de harpa eólia ; o seu amor um desmaio , a su\n",
      "a , porque era insigne na viola e na harpa , não menos que na teologia . Consul\n",
      "oloncelo ; se for menina , aprenderá harpa . São os únicos instrumentos capazes\n",
      "e , mais ainda , um duo admirável de harpa e contrabaixo . Este instrumento foi\n",
      "s amigos ; outra que toma por título Harpa Brasileira , onde estão as poesias A\n",
      "or ele ao nosso idioma . Abro mão da Harpa de Moore ; mas os Mortos de coração \n",
      "essa classificação entre homens . Na Harpa Brasileira encontramos uma parte des\n",
      "ram os coros da peça . Acompanhou na harpa o duo de Elvira e Carlos V a Sra . D\n",
      "lancolicamente a corda harmoniosa da harpa inspirada do Virgílio cristão ! Os a\n",
      " pendurei nos ramos dos salgueiros a harpa das minhas mais caras ilusões , mas \n",
      "vas e do mar . AS BRISAS Deu - nos a harpa eólia a excelsa melodia Que a folhag\n",
      "rmonia , Ao pé da tua voz , filha da harpa do amor ? Diz - nos tu como houveste\n",
      "Fala aos ecos da espessura A chorosa harpa do vento , E num canto sonolento Ent\n",
      "rar , não viu pousar calada , Como a harpa dos êxules profetas , A heróica tuba\n",
      "ristes , Nas débeis cordas de minh  harpa débil ?!... Doce chama me ateias den\n",
      "e sinto ao escutar - te as notas d ' harpa ! A UMA MENINA [ 48 ] La esencia de \n",
      "harmonia Em teus sonoros carmes ! Na harpa d ' ouro Do sacro Apollo , Trovador \n",
      ", quem soubera Imitar de teu peito  harpa celeste - O meigo som , para louvar \n",
      "ão a irmão ! Aos sons acordes da tua harpa ardente Venho juntar uma canção saud\n",
      "emos pois ! Meu tímido alaúde Da tua harpa unirei à nota ardente Em uma só canç\n",
      "os destinos , Imprimiu - te na voz a harpa de um século E a alma te encarnou em\n",
      "nia ... À Babilônia melhor ; levai a harpa do desterro , mas em vez de a pendur\n"
     ]
    }
   ],
   "source": [
    "T.concordance('Harpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
